{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Attempting to install packages into Python executable: /opt/anaconda3/bin/python ---\n",
      "Requirement already satisfied: mediapipe in /opt/anaconda3/lib/python3.12/site-packages (0.10.21)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: pyshine in /Users/casanova/.local/lib/python3.12/site-packages (0.0.9)\n",
      "Requirement already satisfied: celluloid in /Users/casanova/.local/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (24.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (25.1.24)\n",
      "Requirement already satisfied: jax in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: jaxlib in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: numpy<2 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.25.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "--- Installation attempt finished. Check output above for success/errors. ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install packages directly into the kernel's environment\n",
    "import sys\n",
    "print(f\"--- Attempting to install packages into Python executable: {sys.executable} ---\")\n",
    "\n",
    "# Install main dependencies (including celluloid and pyshine)\n",
    "# Using -m pip ensures we use the pip associated with the kernel's python\n",
    "# Added --user flag as a fallback if system-wide installs fail without sudo\n",
    "!\"{sys.executable}\" -m pip install --user mediapipe opencv-python pandas matplotlib pyshine celluloid\n",
    "\n",
    "# Downgrade numpy for mediapipe compatibility in the same environment\n",
    "!\"{sys.executable}\" -m pip install --user numpy==1.26.4\n",
    "\n",
    "print(\"--- Installation attempt finished. Check output above for success/errors. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Kernel/Pip Check ---\n",
      "Kernel executable: /opt/anaconda3/bin/python\n",
      "Python version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]\n",
      "\n",
      "Checking for 'celluloid' package using pip show:\n",
      "Name: celluloid\n",
      "Version: 0.2.0\n",
      "Summary: Easy matplotlib animation.\n",
      "Home-page: https://github.com/jwkvam/celluloid\n",
      "Author: Jacques Kvam\n",
      "Author-email: jwkvam+pypi@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: /Users/casanova/.local/lib/python3.12/site-packages\n",
      "Requires: matplotlib\n",
      "Required-by: \n",
      "\n",
      "Attempting to find 'celluloid' spec using importlib:\n",
      "Importlib found celluloid spec at: /Users/casanova/.local/lib/python3.12/site-packages/celluloid.py\n",
      "--- Check Complete ---\n"
     ]
    }
   ],
   "source": [
    "# NEW CELL - Run this AFTER the !pip install cell\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "print(\"--- Kernel/Pip Check ---\")\n",
    "print(f\"Kernel executable: {sys.executable}\") \n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"\\nChecking for 'celluloid' package using pip show:\")\n",
    "# Use the kernel's executable to run pip show\n",
    "!\"{sys.executable}\" -m pip show celluloid \n",
    "\n",
    "print(\"\\nAttempting to find 'celluloid' spec using importlib:\")\n",
    "try:\n",
    "    spec = importlib.util.find_spec(\"celluloid\")\n",
    "    if spec:\n",
    "        print(f\"Importlib found celluloid spec at: {spec.origin}\")\n",
    "    else:\n",
    "        print(\"Importlib could NOT find celluloid spec.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking importlib: {e}\")\n",
    "    \n",
    "print(\"--- Check Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "from mpl_toolkits import mplot3d\n",
    "from celluloid import Camera\n",
    "from scipy import spatial\n",
    "import pyshine as ps\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(a,b,c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    radians =  np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0]- b[0])\n",
    "    angle = np.abs ( radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360 - angle\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace your existing extractKeypoint function with this corrected version:\n",
    "\n",
    "import os # Make sure os is imported (usually done in the import cell)\n",
    "import pandas as pd # Make sure pandas is imported as pd\n",
    "import cv2 # Make sure cv2 is imported\n",
    "# Make sure mp_pose and mp_drawing are defined globally before this function runs\n",
    "\n",
    "def extractKeypoint(path):\n",
    "    print(f\"Attempting to extract keypoints from: {path}\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"ERROR: Image file not found at {path}\")\n",
    "        return None, None, None, None # Return None values if file missing\n",
    "\n",
    "    IMAGE_FILES = [path]\n",
    "    joint_list_video = pd.DataFrame([]) # Initialize the main DataFrame to collect results\n",
    "    count = 0 # Frame count (relevant if processing multiple files/frames)\n",
    "    \n",
    "    # Initialize output variables to None or empty lists\n",
    "    landmarks_output, keypoints_output, angle_output, image_output = None, [], [], None\n",
    "\n",
    "    try:\n",
    "        # Initialize MediaPipe Pose\n",
    "        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "            \n",
    "            # Loop through image files (in this case, just one)\n",
    "            for idx, file in enumerate(IMAGE_FILES):\n",
    "                image = cv2.imread(file)\n",
    "                if image is None:\n",
    "                    print(f\"ERROR: Failed to read image file {file}\")\n",
    "                    continue # Skip to next file if reading fails\n",
    "\n",
    "                image_output = image.copy() # Store a copy for drawing BEFORE color conversion\n",
    "                \n",
    "                # Prepare image for MediaPipe\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image_rgb.flags.writeable = False\n",
    "                \n",
    "                # Process image with MediaPipe\n",
    "                results = pose.process(image_rgb)\n",
    "                \n",
    "                # Image can be written on again\n",
    "                image_rgb.flags.writeable = True\n",
    "                # Note: image_output remains the BGR version for drawing/returning\n",
    "                \n",
    "                image_h, image_w, _ = image_output.shape # Get dimensions from the output image\n",
    "\n",
    "                # Try processing landmarks if detected\n",
    "                try: \n",
    "                    if results.pose_landmarks:\n",
    "                        landmarks = results.pose_landmarks.landmark\n",
    "                        landmarks_output = results.pose_landmarks # Store the main landmarks object\n",
    "\n",
    "                        # --- Corrected joint_list creation ---\n",
    "                        all_joints_data = [] # Use a list to collect data first (more efficient)\n",
    "                        for i, data_point in enumerate(landmarks):\n",
    "                            joint_data = {\n",
    "                                'frame': count, \n",
    "                                'id': i,\n",
    "                                'x': data_point.x, \n",
    "                                'y': data_point.y,\n",
    "                                'z': data_point.z, \n",
    "                                'vis': data_point.visibility\n",
    "                            }\n",
    "                            all_joints_data.append(joint_data)\n",
    "\n",
    "                        # Create the DataFrame for this image's landmarks *once*\n",
    "                        if all_joints_data: \n",
    "                            joint_list = pd.DataFrame(all_joints_data) \n",
    "                        else:\n",
    "                            joint_list = pd.DataFrame([]) # Empty if no landmarks processed\n",
    "                        # --- End of corrected joint_list creation ---\n",
    "\n",
    "                        # --- Extract specific points needed for angles ---\n",
    "                        # (Ensure these landmarks indices exist before accessing)\n",
    "                        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                        left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                        left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                        right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "                        right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "                        left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "                        right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "                        right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "                        right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "                        # --- Calculate angles ---\n",
    "                        angle_output = [] # Reset angle list for this image\n",
    "                        angle_output.append(int(calculateAngle(right_shoulder, right_elbow, right_wrist)))\n",
    "                        angle_output.append(int(calculateAngle(left_shoulder, left_elbow, left_wrist)))\n",
    "                        angle_output.append(int(calculateAngle(right_elbow, right_shoulder, right_hip)))\n",
    "                        angle_output.append(int(calculateAngle(left_elbow, left_shoulder, left_hip)))\n",
    "                        angle_output.append(int(calculateAngle(right_shoulder, right_hip, right_knee)))\n",
    "                        angle_output.append(int(calculateAngle(left_shoulder, left_hip, left_knee)))\n",
    "                        angle_output.append(int(calculateAngle(right_hip, right_knee, right_ankle)))\n",
    "                        angle_output.append(int(calculateAngle(left_hip, left_knee, left_ankle)))\n",
    "                        \n",
    "                        # --- Create keypoints list ---\n",
    "                        keypoints_output = [] # Reset keypoints list for this image\n",
    "                        for point in landmarks:\n",
    "                             keypoints_output.append({'X': point.x, 'Y': point.y, 'Z': point.z})\n",
    "\n",
    "                        # --- Draw landmarks and text on the BGR image ---\n",
    "                        # (Your code for cv2.putText for angles 1-8 goes here, using 'image_output')\n",
    "                        # Example for angle 1 on right elbow:\n",
    "                        # cv2.putText(image_output, str(1), tuple(np.multiply(right_elbow,[image_w, image_h]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255,255,0], 2 , cv2.LINE_AA)\n",
    "                        # ... add other cv2.putText calls ...\n",
    "\n",
    "                        mp_drawing.draw_landmarks(image_output, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                                mp_drawing.DrawingSpec(color = (0,0,255), thickness = 4, circle_radius = 2),\n",
    "                                                mp_drawing.DrawingSpec(color = (0,255,0),thickness = 4, circle_radius = 2)\n",
    "                                                )\n",
    "                        print(f\"Successfully processed landmarks for {file}\")\n",
    "\n",
    "                    else: # No landmarks detected\n",
    "                        print(f\"Warning: No pose landmarks detected in {file}\")\n",
    "                        joint_list = pd.DataFrame([]) # Ensure joint_list is empty\n",
    "\n",
    "                except Exception as e_inner:\n",
    "                    print(f\"Error processing landmarks in {file}: {e_inner}\")\n",
    "                    joint_list = pd.DataFrame([]) # Ensure joint_list is empty in case of other errors\n",
    "\n",
    "                # --- Corrected outer append using pd.concat ---\n",
    "                # Add the joint_list for this image to the overall joint_list_video\n",
    "                if 'joint_list' in locals() and not joint_list.empty: # Check if joint_list was created and has data\n",
    "                    joint_list_video = pd.concat([joint_list_video, joint_list], ignore_index=True)\n",
    "                # --- End of corrected outer append ---\n",
    "\n",
    "        print(\"extractKeypoint function finished.\")\n",
    "        \n",
    "    except Exception as e_outer:\n",
    "        print(f\"Error initializing MediaPipe Pose or during file loop in extractKeypoint: {e_outer}\")\n",
    "\n",
    "    # Return the results from processing the (last) image\n",
    "    return landmarks_output, keypoints_output, angle_output, image_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPose(landmarks, output_image, display=False):\n",
    "    \n",
    "    # Initialize the label of the pose. It is not known at this stage.\n",
    "    label = 'Unknown Pose'\n",
    "    color = (0, 0, 255)\n",
    "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    left_elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "    left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]    \n",
    "    right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "    right_elbow = landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value]\n",
    "    right_wrist = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
    "    left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "    left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "    left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]            \n",
    "    right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]            \n",
    "    right_knee = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value]\n",
    "    right_ankle = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]              \n",
    "                  \n",
    "    angle1 = calculateAngle(right_shoulder, right_elbow, right_wrist)\n",
    "   \n",
    "    angle2 = calculateAngle(left_shoulder, left_elbow, left_wrist)\n",
    "    \n",
    "    angle3 = calculateAngle(right_elbow, right_shoulder, right_hip)\n",
    "    \n",
    "    angle4 = calculateAngle(left_elbow, left_shoulder, left_hip)\n",
    "    \n",
    "    angle5 = calculateAngle(right_shoulder, right_hip, right_knee)\n",
    "    \n",
    "    angle6 = calculateAngle(left_shoulder, left_hip, left_knee)\n",
    "    \n",
    "    angle7 = calculateAngle(right_hip, right_knee, right_ankle)\n",
    "    \n",
    "    angle8 = calculateAngle(left_hip, left_knee, left_ankle)\n",
    "    \n",
    "\n",
    "    if angle2 > 160 and angle2 < 195 and angle1 > 160 and angle1 < 195:\n",
    "\n",
    "        if angle4 > 70 and angle4 < 110 and angle3 > 70 and angle3 < 110:\n",
    "\n",
    "            if angle8 > 165 and angle8 < 195 or angle7 > 165 and angle7 < 195:\n",
    " \n",
    "\n",
    "                if (angle8 > 80 and angle8 < 120) or (angle7 > 80 and angle7 < 120):\n",
    "\n",
    "                    label = 'Warrior II Pose'             \n",
    "  \n",
    " \n",
    "            if (angle8 > 160 and angle8 < 195) and (angle7 > 160 and angle7 < 195):\n",
    " \n",
    "                label = 'T Pose'\n",
    " \n",
    "\n",
    "    if (angle8 > 165 and angle8 < 195) or (angle7 > 165 and angle7 < 195):\n",
    "\n",
    "        if (angle7 > 25 and angle7 < 45) or (angle8 > 25 and angle8 < 45):\n",
    " \n",
    "            label = 'Tree Pose'\n",
    "\n",
    "    if label != 'Unknown Pose':\n",
    "\n",
    "        color = (0, 0, 255)  \n",
    "\n",
    "    cv2.putText(output_image, label, (400, 50),cv2.FONT_HERSHEY_PLAIN, 4, color, 4)\n",
    "    cv2.rectangle(output_image,(0,0), (100,255), (255,255,255), -1)\n",
    "\n",
    "    cv2.putText(output_image, 'ID', (10,14), cv2.FONT_HERSHEY_SIMPLEX, 0.6, [0,0,255], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(1), (10,40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(2), (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(3), (10,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(4), (10,130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(5), (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(6), (10,190), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(7), (10,220), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(8), (10,250), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.putText(output_image, 'Angle', (40,12), cv2.FONT_HERSHEY_SIMPLEX, 0.6, [0,0,255], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(int(angle1)), (40,40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(int(angle2)), (40,70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(int(angle3)), (40,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(int(angle4)), (40,130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(int(angle5)), (40,160), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(int(angle6)), (40,190), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(int(angle7)), (40,220), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_image, str(int(angle8)), (40,250), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "\n",
    "    if display:\n",
    "    \n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "        \n",
    "    else:\n",
    "\n",
    "        return output_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image, pose, display=True):\n",
    " \n",
    "    output_image = image.copy()\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imageRGB) \n",
    "    height, width, _ = image.shape\n",
    "    landmarks = []\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        mp_drawing.draw_landmarks(output_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                         mp_drawing.DrawingSpec(color = (0,0,255), thickness = 5, circle_radius = 2),\n",
    "                         mp_drawing.DrawingSpec(color = (0,255,0),thickness = 5, circle_radius = 2)\n",
    "                         )\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            \n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                                  (landmark.z * width)))\n",
    "    if display:\n",
    "        plt.figure(figsize=[22,22])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    else:\n",
    "        return output_image, landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pose(image,angle_point,angle_user, angle_target ):\n",
    "    angle_user = np.array(angle_user)\n",
    "    angle_target = np.array(angle_target)\n",
    "    angle_point = np.array(angle_point)\n",
    "    stage = 0\n",
    "    cv2.rectangle(image,(0,0), (370,40), (255,255,255), -1)\n",
    "    cv2.rectangle(image,(0,40), (370,370), (255,255,255), -1)\n",
    "    cv2.putText(image, str(\"Score:\"), (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "    height, width, _ = image.shape   \n",
    "    \n",
    "    if angle_user[0] < (angle_target[0] - 15):\n",
    "        #print(\"Extend the right arm at elbow\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Extend the right arm at elbow\"), (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[0][0]*width), int(angle_point[0][1]*height)),30,(0,0,255),5) \n",
    "        \n",
    "    if angle_user[0] > (angle_target[0] + 15):\n",
    "        #print(\"Fold the right arm at elbow\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Fold the right arm at elbow\"), (10,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[0][0]*width), int(angle_point[0][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "        \n",
    "    if angle_user[1] < (angle_target[1] -15):\n",
    "        #print(\"Extend the left arm at elbow\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Extend the left arm at elbow\"), (10,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[1][0]*width), int(angle_point[1][1]*height)),30,(0,0,255),5)\n",
    "        \n",
    "    if angle_user[1] >(angle_target[1] + 15):\n",
    "        #print(\"Fold the left arm at elbow\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Fold the left arm at elbow\"), (10,120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[1][0]*width), int(angle_point[1][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "        \n",
    "    if angle_user[2] < (angle_target[2] - 15):\n",
    "        #print(\"Lift your right arm\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Lift your right arm\"), (10,140), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[2][0]*width), int(angle_point[2][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "    if angle_user[2] > (angle_target[2] + 15):\n",
    "        #print(\"Put your arm down a little\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Put your arm down a little\"), (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[2][0]*width), int(angle_point[2][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "    if angle_user[3] < (angle_target[3] - 15):\n",
    "        #print(\"Lift your left arm\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Lift your left arm\"), (10,180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[3][0]*width), int(angle_point[3][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "    if angle_user[3] > (angle_target[3] + 15):\n",
    "        #print(\"Put your arm down a little\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Put your arm down a little\"), (10,200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[3][0]*width), int(angle_point[3][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "    if angle_user[4] < (angle_target[4] - 15):\n",
    "        #print(\"Extend the angle at right hip\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Extend the angle at right hip\"), (10,220), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[4][0]*width), int(angle_point[4][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "    if angle_user[4] > (angle_target[4] + 15):\n",
    "        #print(\"Reduce the angle at right hip\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Reduce the angle of at right hip\"), (10,240), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[4][0]*width), int(angle_point[4][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "    if angle_user[5] < (angle_target[5] - 15):\n",
    "        #print(\"Extend the angle at left hip\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Extend the angle at left hip\"), (10,260), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[5][0]*width), int(angle_point[5][1]*height)),30,(0,0,255),5)\n",
    "        \n",
    "\n",
    "    if angle_user[5] > (angle_target[5] + 15):\n",
    "        #print(\"Reduce the angle at left hip\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Reduce the angle at left hip\"), (10,280), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[5][0]*width), int(angle_point[5][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "    if angle_user[6] < (angle_target[6] - 15):\n",
    "        #print(\"Extend the angle of right knee\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Extend the angle of right knee\"), (10,300), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[6][0]*width), int(angle_point[6][1]*height)),30,(0,0,255),5)\n",
    "        \n",
    "\n",
    "    if angle_user[6] > (angle_target[6] + 15):\n",
    "        #print(\"Reduce the angle of right knee\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Reduce the angle at right knee\"), (10,320), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[6][0]*width), int(angle_point[6][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "\n",
    "    if angle_user[7] < (angle_target[7] - 15):\n",
    "        #print(\"Extend the angle at left knee\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Extend the angle at left knee\"), (10,340), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[7][0]*width), int(angle_point[7][1]*height)),30,(0,0,255),5)\n",
    "\n",
    "    if angle_user[7] > (angle_target[7] + 15):\n",
    "        #print(\"Reduce the angle at left knee\")\n",
    "        stage = stage + 1\n",
    "        cv2.putText(image, str(\"Reduce the angle at left knee\"), (10,360), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "        cv2.circle(image,(int(angle_point[7][0]*width), int(angle_point[7][1]*height)),30,(0,0,255),5)\n",
    "    \n",
    "    if stage!=0:\n",
    "        #print(\"FIGHTING!\")\n",
    "        cv2.putText(image, str(\"FIGHTING!\"), (170,30), cv2.FONT_HERSHEY_SIMPLEX, 1, [0,0,255], 2, cv2.LINE_AA)\n",
    "        \n",
    "        pass\n",
    "    else:\n",
    "        #print(\"PERFECT\")\n",
    "        cv2.putText(image, str(\"PERFECT\"), (170,30), cv2.FONT_HERSHEY_SIMPLEX, 1, [0,0,255], 2, cv2.LINE_AA)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dif_compare(x,y):\n",
    "    average = []\n",
    "    for i,j in zip(range(len(list(x))),range(len(list(y)))):\n",
    "        result = 1 - spatial.distance.cosine(list(x[i].values()),list(y[j].values()))\n",
    "        average.append(result)\n",
    "    score = math.sqrt(2*(1-round(Average(average),2)))\n",
    "    #print(Average(average))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_compare_angle(x,y):\n",
    "    new_x = []\n",
    "    for i,j in zip(range(len(x)),range(len(y))):\n",
    "        z = np.abs(x[i] - y[j])/((x[i]+ y[j])/2)\n",
    "        new_x.append(z)\n",
    "        #print(new_x[i])\n",
    "    return Average(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(landmarks):\n",
    "    df = pd.DataFrame(columns = ['x', 'y', 'z', 'vis'])\n",
    "    for i in range(len(landmarks)):\n",
    "        df = df.append({\"x\": landmarks[i].x,\n",
    "                        \"y\": landmarks[i].y,\n",
    "                        \"z\": landmarks[i].z,\n",
    "                        \"vis\": landmarks[i].visibility\n",
    "                                     }, ignore_index= True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to extract keypoints from: Video/yoga11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1769777754.654590 5389668 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1\n",
      "W0000 00:00:1769777754.749064 5433655 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1769777754.766867 5433662 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1769777754.847673 5389668 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed landmarks for Video/yoga11.jpg\n",
      "extractKeypoint function finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1769777755.022082 5433690 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1769777755.044759 5433690 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# path = \"Video/yoga19.jpg\"\n",
    "\n",
    "bike = 4\n",
    " \n",
    "if bike == 2:\n",
    "    path = \"Video/yoga19.jpg\"\n",
    " \n",
    "elif bike == 3:\n",
    "    path = \"Video/yoga25.jpg\"\n",
    "\n",
    " \n",
    "elif bike == 4:\n",
    "    path = \"Video/yoga11.jpg\"\n",
    "\n",
    "elif bike == 5:\n",
    "    path = \"Video/yoga12.jpg\"\n",
    "    \n",
    "elif bike == 6:\n",
    "    path = \"Video/yoga8.jpg\"\n",
    "    \n",
    "elif bike == 7:\n",
    "    path = \"Video/yoga9.jpg\"\n",
    "\n",
    "elif bike == 8:\n",
    "    path = \"Video/yoga10.jpg\"\n",
    "    \n",
    "else:\n",
    "    path = \"Video/yoga16.jpg\"\n",
    "\n",
    "                \n",
    "x = extractKeypoint( path)\n",
    "dim = (560, 360)\n",
    "resized = cv2.resize(x[3], dim, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('target',resized)\n",
    "angle_target = x[2]\n",
    "point_target = x[1]\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence =0.5, min_tracking_confidence = 0.5) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret,frame= cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image_height, image_width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(image_width * (860 / image_height)), 860))\n",
    "        # finding the distance by calling function\n",
    "        # Distance distance finder function need\n",
    "        # these arguments the Focal_Length,\n",
    "        # Known_width(centimeters),\n",
    "        # and Known_distance(centimeters)\n",
    "  \n",
    "        #\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z,\n",
    "                          round(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility*100, 2)]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z,\n",
    "                          round(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].visibility*100, 2)]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].z,\n",
    "                          round(landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].visibility*100, 2)]\n",
    "            \n",
    "            angle_point = []\n",
    "            \n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            angle_point.append(right_elbow)\n",
    "            \n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            angle_point.append(left_elbow)\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            angle_point.append(right_shoulder)\n",
    "            \n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            angle_point.append(left_shoulder)\n",
    "            \n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                    \n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            angle_point.append(right_hip)\n",
    "            \n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            angle_point.append(left_hip)\n",
    "            \n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            angle_point.append(right_knee)\n",
    "            \n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            angle_point.append(left_knee)\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            \n",
    "            \n",
    "            keypoints = []\n",
    "            for point in landmarks:\n",
    "                keypoints.append({\n",
    "                     'X': point.x,\n",
    "                     'Y': point.y,\n",
    "                     'Z': point.z,\n",
    "                     })\n",
    "            \n",
    "            p_score = dif_compare(keypoints, point_target)      \n",
    "            \n",
    "            angle = []\n",
    "            \n",
    "            angle1 = calculateAngle(right_shoulder, right_elbow, right_wrist)\n",
    "            angle.append(int(angle1))\n",
    "            angle2 = calculateAngle(left_shoulder, left_elbow, left_wrist)\n",
    "            angle.append(int(angle2))\n",
    "            angle3 = calculateAngle(right_elbow, right_shoulder, right_hip)\n",
    "            angle.append(int(angle3))\n",
    "            angle4 = calculateAngle(left_elbow, left_shoulder, left_hip)\n",
    "            angle.append(int(angle4))\n",
    "            angle5 = calculateAngle(right_shoulder, right_hip, right_knee)\n",
    "            angle.append(int(angle5))\n",
    "            angle6 = calculateAngle(left_shoulder, left_hip, left_knee)\n",
    "            angle.append(int(angle6))\n",
    "            angle7 = calculateAngle(right_hip, right_knee, right_ankle)\n",
    "            angle.append(int(angle7))\n",
    "            angle8 = calculateAngle(left_hip, left_knee, left_ankle)\n",
    "            angle.append(int(angle8))\n",
    "            \n",
    "            compare_pose(image, angle_point,angle, angle_target)\n",
    "            a_score = diff_compare_angle(angle,angle_target)\n",
    "            \n",
    "            if (p_score >= a_score):\n",
    "                cv2.putText(image, str(int((1 - a_score)*100)), (80,30), cv2.FONT_HERSHEY_SIMPLEX, 1, [0,0,255], 2, cv2.LINE_AA)\n",
    "\n",
    "            else:\n",
    "                cv2.putText(image, str(int((1 - p_score)*100)), (80,30), cv2.FONT_HERSHEY_SIMPLEX, 1, [0,0,255], 2, cv2.LINE_AA)\n",
    " \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color = (0,0,255), thickness = 4, circle_radius = 4),\n",
    "                                 mp_drawing.DrawingSpec(color = (0,255,0),thickness = 3, circle_radius = 3)\n",
    "                                  )\n",
    "\n",
    "\n",
    "#         cv2.putText(output_image, 'ID', (10,14), cv2.FONT_HERSHEY_SIMPLEX, 0.6, [0,0,255], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(1), (10,40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(2), (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(3), (10,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(4), (10,130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(5), (10,160), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(6), (10,190), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(7), (10,220), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(8), (10,250), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "\n",
    "#         cv2.putText(output_image, 'Angle', (40,12), cv2.FONT_HERSHEY_SIMPLEX, 0.6, [0,0,255], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(int(angle1)), (40,40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(int(angle2)), (40,70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(int(angle3)), (40,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(int(angle4)), (40,130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(int(angle5)), (40,160), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(int(angle6)), (40,190), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(int(angle7)), (40,220), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_image, str(int(angle8)), (40,250), cv2.FONT_HERSHEY_SIMPLEX, 0.7, [0,153,0], 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cv2.imshow('MediaPipe Feed',image)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
